{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6N22Uz-kLiZW"
   },
   "source": [
    "### Main imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MK1Jl7nkLnPA",
    "outputId": "140fac74-15b2-4d66-ea7c-ea799d544617"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display as disp\n",
    "from pathlib import Path\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('Device:', device.type)\n",
    "print('Imports complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3sLAPCRM6_h"
   },
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bK383zeDM4Ac",
    "outputId": "b6597294-6f1d-4372-8c51-f08072bc78ab"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# directory where the data is stored\n",
    "data_dir = 'classification-data'\n",
    "\n",
    "# the .npy files\n",
    "train_x_path = os.path.join(data_dir, 'train_x.npy')\n",
    "train_y_path = os.path.join(data_dir, 'train_y.npy')\n",
    "valid_x_path = os.path.join(data_dir, 'valid_x.npy')\n",
    "valid_y_path = os.path.join(data_dir, 'valid_y.npy')\n",
    "test_x_path = os.path.join(data_dir, 'test_x.npy')\n",
    "test_y_path = os.path.join(data_dir, 'test_y.npy')\n",
    "\n",
    "# load the data\n",
    "print(\"Loading data...\")\n",
    "train_x = numpy.load(train_x_path)\n",
    "train_y = numpy.load(train_y_path)\n",
    "valid_x = numpy.load(valid_x_path)\n",
    "valid_y = numpy.load(valid_y_path)\n",
    "test_x = numpy.load(test_x_path)\n",
    "test_y = numpy.load(test_y_path)\n",
    "print(\"Data loaded successfully.\")\n",
    "\n",
    "print(\"Shape of one training sample:\", train_x.shape[1:])\n",
    "print(\"Shape of one validation sample:\", valid_x.shape[1:])\n",
    "print(\"Shape of one test sample:\", test_x.shape[1:])\n",
    "\n",
    "train_x = train_x.reshape(-1, 3, 28, 28) \n",
    "valid_x = valid_x.reshape(-1, 3, 28, 28) \n",
    "test_x = test_x.reshape(-1, 3, 28, 28)\n",
    "\n",
    "print(\"Shape of one training sample:\", train_x.shape[1:])\n",
    "print(\"Shape of one validation sample:\", valid_x.shape[1:])\n",
    "print(\"Shape of one test sample:\", test_x.shape[1:])\n",
    "\n",
    "# convert NumPy arrays to PyTorch tensors - HAS BEEN CHANGED FOR THE ABOVE\n",
    "train_x = torch.from_numpy(train_x).float()\n",
    "train_y = torch.from_numpy(train_y).long()\n",
    "valid_x = torch.from_numpy(valid_x).float()\n",
    "\n",
    "valid_y = torch.from_numpy(valid_y).long()\n",
    "test_x = torch.from_numpy(test_x).float()\n",
    "test_y = torch.from_numpy(test_y).long()\n",
    "\n",
    "# create TensorDataset instances\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "valid_dataset = TensorDataset(valid_x, valid_y)\n",
    "test_dataset = TensorDataset(test_x, test_y)\n",
    "\n",
    "# batch size\n",
    "batch_size = 64\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "# Helper function to cycle through the data indefinitely\n",
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for x in iterable:\n",
    "            yield x\n",
    "\n",
    "# iterators for training, validation, and test loaders\n",
    "train_iterator = iter(cycle(train_loader))\n",
    "valid_iterator = iter(cycle(valid_loader))\n",
    "test_iterator = iter(cycle(test_loader))\n",
    "\n",
    "# class names\n",
    "class_names = [str(i) for i in range(20)]\n",
    "\n",
    "# dataset sizes\n",
    "print(f'> Size of training dataset: {len(train_dataset)}')\n",
    "print(f'> Size of validation dataset: {len(valid_dataset)}')\n",
    "print(f'> Size of test dataset: {len(test_dataset)}')\n",
    "\n",
    "num_batches_per_epoch = len(train_loader) // batch_size\n",
    "\n",
    "num_of_epochs = 10000 // num_batches_per_epoch\n",
    "\n",
    "print(f'Number of batches per epoch: {num_batches_per_epoch}')\n",
    "print(f'Number of epochs: {num_of_epochs}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-FdW5HnimG2"
   },
   "source": [
    "**View some of the test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 583
    },
    "id": "BtJs-qxHRLXz",
    "outputId": "9e93788b-f953-48a6-b4b4-a64eb385563c"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 70\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    img = test_loader.dataset[i][0].numpy().transpose(1, 2, 0)\n",
    "    img = numpy.clip(img, 0, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.xlabel(class_names[test_loader.dataset[i][1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(EfficientResidualBlock, self).__init__()\n",
    "        # Reduced intermediate channels by using a bottleneck design\n",
    "        mid_channels = out_channels // 4\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(mid_channels)\n",
    "        self.conv2 = nn.Conv2d(mid_channels, mid_channels, kernel_size=3,\n",
    "                              stride=stride, padding=1, groups=mid_channels, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(mid_channels)\n",
    "        self.conv3 = nn.Conv2d(mid_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # self.shortcut = nn.Sequential()\n",
    "        # if stride != 1 or in_channels != out_channels:\n",
    "        #     self.shortcut = nn.Sequential(\n",
    "        #         nn.Conv2d(in_channels, out_channels, kernel_size=1,\n",
    "        #                  stride=stride, bias=False),\n",
    "        #         nn.BatchNorm2d(out_channels)\n",
    "        #     )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        \n",
    "        # out += self.shortcut(residual)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class EfficientResNet32x32(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(EfficientResNet32x32, self).__init__()\n",
    "        \n",
    "        # Reduced initial channels\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # Reduced channel dimensions throughout\n",
    "        self.layer1 = self._make_layer(32, 64, stride=1)\n",
    "        self.layer2 = self._make_layer(64, 128, stride=2)\n",
    "        self.layer3 = self._make_layer(128, 256, stride=2)\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def _make_layer(self, in_channels, out_channels, stride):\n",
    "        return nn.Sequential(\n",
    "            EfficientResidualBlock(in_channels, out_channels, stride),\n",
    "            # EfficientResidualBlock(out_channels, out_channels, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "def create_model(num_classes=100, device='cuda'):\n",
    "    model = EfficientResNet32x32(num_classes=num_classes)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    return model, optimizer, criterion\n",
    "\n",
    "model, optimizer, criterion = create_model(num_classes=100, device=device)\n",
    "\n",
    "print(\"Parameter count:\", sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1UBl0PJjY-f"
   },
   "source": [
    "### Main training and testing loop - Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "id": "kb5909Y8D_zx",
    "outputId": "fe198374-76f9-486e-e30c-c5ea42080981"
   },
   "outputs": [],
   "source": [
    "save_dir = Path('checkpoints')\n",
    "save_dir.mkdir(exist_ok=True)\n",
    "best_acc = 0.0\n",
    "epoch = 1\n",
    "batch_size = train_loader.batch_size\n",
    "check_interval = 5\n",
    "\n",
    "# training loop\n",
    "while (epoch < num_of_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # arrays for metrics\n",
    "    logs = {}\n",
    "    train_loss_arr = np.zeros(0)\n",
    "    train_acc_arr = np.zeros(0)\n",
    "    \n",
    "    # iterate over the train dataset\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        x, t = batch\n",
    "        x, t = x.to(device), t.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, t)\n",
    "        \n",
    "        # backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # calculate accuracy\n",
    "        _, predicted = outputs.max(1)\n",
    "        accuracy = predicted.eq(t).sum().item() / t.size(0) * 100\n",
    "        \n",
    "        # store metrics\n",
    "        train_loss_arr = np.append(train_loss_arr, loss.item())\n",
    "        train_acc_arr = np.append(train_acc_arr, accuracy)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_of_epochs}], Batch [{i+1}/{len(train_loader)}], '\n",
    "                f'Loss: {train_loss_arr.mean():.4f}, Accuracy: {train_acc_arr.mean():.2f}%')\n",
    "    \n",
    "    # validation check at specified intervals\n",
    "    if (epoch + 1) % check_interval == 0:\n",
    "        model.eval()\n",
    "        val_loss_arr = np.zeros(0)\n",
    "        val_acc_arr = np.zeros(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for val_x, val_t in test_loader: # this might be incorrect for the loop\n",
    "                val_x, val_t = val_x.to(device), val_t.to(device)\n",
    "                val_outputs = model(val_x)\n",
    "                val_loss = criterion(val_outputs, val_t)\n",
    "                \n",
    "                _, val_predicted = val_outputs.max(1)\n",
    "                val_accuracy = val_predicted.eq(val_t).sum().item() / val_t.size(0) * 100\n",
    "                \n",
    "                val_loss_arr = np.append(val_loss_arr, val_loss.item())\n",
    "                val_acc_arr = np.append(val_acc_arr, val_accuracy)\n",
    "            \n",
    "            print(f'\\nValidation at Epoch [{epoch+1}/{num_of_epochs}], '\n",
    "                    f'Loss: {val_loss_arr.mean():.4f}, Accuracy: {val_acc_arr.mean():.2f}%')\n",
    "            \n",
    "            # save best model\n",
    "            if val_acc_arr.mean() > best_acc:\n",
    "                best_acc = val_acc_arr.mean()\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'accuracy': best_acc,\n",
    "                }\n",
    "                torch.save(checkpoint, save_dir / 'best_model.pth')\n",
    "                print(f'New best validation accuracy: {best_acc:.2f}%')\n",
    "            \n",
    "            # visualize random batch of training images\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.axis('off')\n",
    "            plt.title(f'Training Images at Epoch {epoch+1}')\n",
    "            plt.imshow(np.transpose(\n",
    "                torchvision.utils.make_grid(x[:batch_size], padding=2, normalize=True).cpu(),\n",
    "                (1, 2, 0)\n",
    "            ))\n",
    "            plt.show()\n",
    "        \n",
    "        model.train()\n",
    "    \n",
    "    print(f\"Epoch {epoch} / {num_of_epochs}\")\n",
    "    epoch += 1\n",
    "\n",
    "print('\\nTraining completed!')\n",
    "print(f'Best validation accuracy: {best_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTFqiEHzMOVw"
   },
   "source": [
    "## Inference on data\n",
    "\n",
    "This is useful for analysis but is entirely optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 907
    },
    "id": "kTzXmAdQK2c2",
    "outputId": "447feb45-9891-4a66-bdce-36e3830c2b0e"
   },
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "    img = numpy.clip(img, 0, 1)\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    img = numpy.transpose(img, (1, 2, 0))\n",
    "    plt.imshow(img)\n",
    "\n",
    "    predicted_label = numpy.argmax(predictions_array)\n",
    "    color = '#335599' if predicted_label == true_label else '#ee4433'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                  100*numpy.max(predictions_array),\n",
    "                                  class_names[true_label]),\n",
    "                                  color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(20), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = numpy.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('#ee4433')\n",
    "    thisplot[true_label].set_color('#335599')\n",
    "\n",
    "test_images, test_labels = next(test_iterator)\n",
    "test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
    "test_preds = torch.softmax(N(test_images), dim=1).data.cpu().numpy()\n",
    "num_rows = 8\n",
    "num_cols = 4\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    plot_image(i, test_preds, test_labels.cpu().numpy(), test_images.cpu().numpy()) # Used .numpy() here\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "    plot_value_array(i, test_preds, test_labels.cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
