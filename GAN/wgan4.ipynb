{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display as disp\n",
    "from torch.nn.utils import spectral_norm    \n",
    "from torch import optim;\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device.type)\n",
    "\n",
    "# helper function to make getting another batch of data easier\n",
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for x in iterable:\n",
    "            yield x\n",
    "\n",
    "class_names = ['apple','aquarium_fish','baby','bear','beaver','bed','bee','beetle','bicycle','bottle','bowl','boy','bridge','bus','butterfly','camel','can','castle','caterpillar','cattle','chair','chimpanzee','clock','cloud','cockroach','couch','crab','crocodile','cup','dinosaur','dolphin','elephant','flatfish','forest','fox','girl','hamster','house','kangaroo','computer_keyboard','lamp','lawn_mower','leopard','lion','lizard','lobster','man','maple_tree','motorcycle','mountain','mouse','mushroom','oak_tree','orange','orchid','otter','palm_tree','pear','pickup_truck','pine_tree','plain','plate','poppy','porcupine','possum','rabbit','raccoon','ray','road','rocket','rose','sea','seal','shark','shrew','skunk','skyscraper','snail','snake','spider','squirrel','streetcar','sunflower','sweet_pepper','table','tank','telephone','television','tiger','tractor','train','trout','tulip','turtle','wardrobe','whale','willow_tree','wolf','woman','worm',]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.CIFAR100('data', train=True, download=True, transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])),\n",
    "    batch_size=64, drop_last=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.CIFAR100('data', train=False, download=True, transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize([32,32]),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])),\n",
    "    batch_size=64, drop_last=True)\n",
    "\n",
    "train_iterator = iter(cycle(train_loader))\n",
    "test_iterator = iter(cycle(test_loader))\n",
    "\n",
    "print(f'> Size of training dataset {len(train_loader.dataset)}')\n",
    "print(f'> Size of test dataset {len(test_loader.dataset)}')\n",
    "print(\"Number of classes: \", len(class_names))\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "num_batches_per_epoch = len(train_loader.dataset) // batch_size\n",
    "\n",
    "print(\"Length of train_loader: \", len(train_loader.dataset))\n",
    "\n",
    "num_of_epochs = 50000 // num_batches_per_epoch\n",
    "\n",
    "print(\"Number of batches per epoch: \", num_batches_per_epoch)\n",
    "print(\"Number of epochs: \", num_of_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "from typing import List, Tuple, Optional\n",
    "import logging\n",
    "import os\n",
    "\n",
    "class CompactResBlock(nn.Module):\n",
    "    def __init__(self, channels: int):\n",
    "        super(CompactResBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(channels, channels, 1),\n",
    "            nn.BatchNorm2d(channels)\n",
    "        )\n",
    "        self.activation = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.activation(x + self.block(x))\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim: int = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # Architecture dimensions\n",
    "        self.latent_dim = latent_dim\n",
    "        self.init_size = 4  # Starting spatial size\n",
    "        self.init_channels = 512  # Initial number of channels\n",
    "        \n",
    "        # Project and reshape\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Linear(latent_dim, self.init_channels * self.init_size * self.init_size),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Main convolutional sequence\n",
    "        self.main = nn.Sequential(\n",
    "            # 4x4x512 -> 8x8x256\n",
    "            nn.BatchNorm2d(self.init_channels),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(self.init_channels, self.init_channels // 2, 3, 1, 1),\n",
    "            CompactResBlock(self.init_channels // 2),\n",
    "            \n",
    "            # 8x8x256 -> 16x16x128\n",
    "            nn.BatchNorm2d(self.init_channels // 2),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(self.init_channels // 2, self.init_channels // 4, 3, 1, 1),\n",
    "            CompactResBlock(self.init_channels // 4),\n",
    "            \n",
    "            # 16x16x128 -> 32x32x64\n",
    "            nn.BatchNorm2d(self.init_channels // 4),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(self.init_channels // 4, self.init_channels // 8, 3, 1, 1),\n",
    "            CompactResBlock(self.init_channels // 8),\n",
    "            \n",
    "            # Final layer to get 3 channels\n",
    "            nn.Conv2d(self.init_channels // 8, 3, 3, 1, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        # Project and reshape\n",
    "        out = self.project(z)\n",
    "        out = out.view(-1, self.init_channels, self.init_size, self.init_size)\n",
    "        # Apply main convolutional sequence\n",
    "        return self.main(out)\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        # Initial number of channels in critic\n",
    "        init_channels = 64\n",
    "        \n",
    "        # Main convolutional sequence\n",
    "        self.main = nn.Sequential(\n",
    "            # 32x32x3 -> 16x16x64\n",
    "            spectral_norm(nn.Conv2d(3, init_channels, 4, 2, 1)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            CompactResBlock(init_channels),\n",
    "            \n",
    "            # 16x16x64 -> 8x8x128\n",
    "            spectral_norm(nn.Conv2d(init_channels, init_channels * 2, 4, 2, 1)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            CompactResBlock(init_channels * 2),\n",
    "            \n",
    "            # 8x8x128 -> 4x4x256\n",
    "            spectral_norm(nn.Conv2d(init_channels * 2, init_channels * 4, 4, 2, 1)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            CompactResBlock(init_channels * 4),\n",
    "        )\n",
    "        \n",
    "        # Critic head\n",
    "        self.critic_head = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            spectral_norm(nn.Linear(init_channels * 4 * 4 * 4, 1))\n",
    "        )\n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, img: torch.Tensor) -> torch.Tensor:\n",
    "        features = self.main(img)\n",
    "        return self.critic_head(features)\n",
    "\n",
    "class WGAN:\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim: int = 128,\n",
    "        lr: float = 2e-4,\n",
    "        betas: Tuple[float, float] = (0.5, 0.999),\n",
    "        n_critic: int = 3,\n",
    "        gp_weight: float = 10.0,\n",
    "        device: str = 'cuda',\n",
    "        class_names: Optional[List[str]] = None\n",
    "    ):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.n_critic = n_critic\n",
    "        self.gp_weight = gp_weight\n",
    "        self.device = device\n",
    "        self.class_names = class_names\n",
    "        \n",
    "        # Initialize networks\n",
    "        self.generator = Generator(latent_dim).to(device)\n",
    "        self.critic = Critic().to(device)\n",
    "        \n",
    "        # Print model parameters for verification\n",
    "        generator_params = sum(p.numel() for p in self.generator.parameters())\n",
    "        critic_params = sum(p.numel() for p in self.critic.parameters())\n",
    "        print(f\"Generator parameters: {generator_params:,}\")\n",
    "        print(f\"Critic parameters: {critic_params:,}\")\n",
    "        \n",
    "        # Optimizers\n",
    "        self.optimizer_G = optim.Adam(\n",
    "            self.generator.parameters(),\n",
    "            lr=lr,\n",
    "            betas=betas\n",
    "        )\n",
    "        self.optimizer_C = optim.Adam(\n",
    "            self.critic.parameters(),\n",
    "            lr=lr,\n",
    "            betas=betas\n",
    "        )\n",
    "        \n",
    "        # Training state\n",
    "        self.steps = 0\n",
    "        self.G_losses = []\n",
    "        self.C_losses = []\n",
    "\n",
    "    def compute_gradient_penalty(self, real_samples: torch.Tensor, fake_samples: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size = real_samples.size(0)\n",
    "        # Use uniform sampling instead of random for better coverage\n",
    "        alpha = torch.rand(batch_size, 1, 1, 1, device=self.device, requires_grad=True)\n",
    "        \n",
    "        # More numerically stable interpolation\n",
    "        interpolates = real_samples + alpha * (fake_samples - real_samples)\n",
    "        \n",
    "        d_interpolates = self.critic(interpolates)\n",
    "        \n",
    "        # Use ones_like instead of manual creation for better clarity and stability\n",
    "        fake = torch.ones_like(d_interpolates, requires_grad=False)\n",
    "        \n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs=d_interpolates,\n",
    "            inputs=interpolates,\n",
    "            grad_outputs=fake,\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            only_inputs=True\n",
    "        )[0]\n",
    "        \n",
    "        # L2 norm calculation with epsilon for numerical stability\n",
    "        gradients = gradients.view(batch_size, -1)\n",
    "        gradient_norm = torch.sqrt(torch.sum(gradients ** 2, dim=1) + 1e-12)\n",
    "        gradient_penalty = ((gradient_norm - 1) ** 2).mean()\n",
    "        \n",
    "        return gradient_penalty\n",
    "\n",
    "    def train_step(self, real_imgs: torch.Tensor) -> Tuple[Optional[float], float]:\n",
    "        batch_size = real_imgs.size(0)\n",
    "        real_imgs = real_imgs.to(self.device)\n",
    "        \n",
    "        # Train Critic\n",
    "        self.optimizer_C.zero_grad()\n",
    "        \n",
    "        z = torch.randn(batch_size, self.latent_dim, device=self.device)\n",
    "        fake_imgs = self.generator(z).detach()\n",
    "        \n",
    "        real_validity = self.critic(real_imgs)\n",
    "        fake_validity = self.critic(fake_imgs)\n",
    "        \n",
    "        gradient_penalty = self.compute_gradient_penalty(real_imgs, fake_imgs)\n",
    "        \n",
    "        critic_loss = torch.mean(fake_validity) - torch.mean(real_validity) + \\\n",
    "                     self.gp_weight * gradient_penalty\n",
    "        \n",
    "        critic_loss.backward()\n",
    "\n",
    "        self.optimizer_C.step()\n",
    "        \n",
    "        self.C_losses.append(critic_loss.item())\n",
    "        \n",
    "        # Train Generator\n",
    "        generator_loss = None\n",
    "        if self.steps % self.n_critic == 0:\n",
    "            self.optimizer_G.zero_grad()\n",
    "            \n",
    "            gen_imgs = self.generator(z)\n",
    "            gen_validity = self.critic(gen_imgs)\n",
    "            \n",
    "            generator_loss = -torch.mean(gen_validity)\n",
    "            generator_loss.backward()\n",
    "            \n",
    "            self.optimizer_G.step()\n",
    "            \n",
    "            self.G_losses.append(generator_loss.item())\n",
    "        \n",
    "        self.steps += 1\n",
    "\n",
    "        return generator_loss.item() if generator_loss is not None else None, critic_loss.item()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate_samples(self, n_samples: int) -> torch.Tensor:\n",
    "        \"\"\"Generate samples with the current generator\"\"\"\n",
    "        self.generator.eval()\n",
    "        z = torch.randn(n_samples, self.latent_dim, device=self.device)\n",
    "        samples = self.generator(z)\n",
    "        self.generator.train()\n",
    "        return samples\n",
    "\n",
    "def train_wgan(\n",
    "    train_iterator,\n",
    "    num_batches_per_epoch: int,\n",
    "    num_of_epochs: int,\n",
    "    device: str = 'cuda',\n",
    "    class_names: Optional[List[str]] = None\n",
    ") -> WGAN:\n",
    "    \"\"\"Training function for the WGAN\"\"\"\n",
    "    save_dir = 'generated_images'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    wgan = WGAN(\n",
    "        latent_dim=128,\n",
    "        lr=2e-4,\n",
    "        n_critic=3,\n",
    "        device=device,\n",
    "        class_names=class_names\n",
    "    )\n",
    "\n",
    "\n",
    "    total_steps = num_batches_per_epoch * num_of_epochs\n",
    "    \n",
    "    print(f\"Training for {total_steps} total steps across {num_of_epochs} epochs\")\n",
    "    \n",
    "    for epoch in range(num_of_epochs):\n",
    "        for batch in range(num_batches_per_epoch):\n",
    "            real_imgs, _ = next(train_iterator)\n",
    "            \n",
    "            g_loss, c_loss = wgan.train_step(real_imgs)\n",
    "            current_step = epoch * num_batches_per_epoch + batch\n",
    "            \n",
    "            if current_step % 100 == 0:\n",
    "                print(f\"[Epoch {epoch}/{num_of_epochs}] \"\n",
    "                      f\"[Batch {batch}/{num_batches_per_epoch}] \"\n",
    "                      f\"[Step {current_step}/{total_steps}] \"\n",
    "                      f\"[C loss: {c_loss:.4f}] \"\n",
    "                      + (f\"[G loss: {g_loss:.4f}]\" if g_loss is not None else \"\"))\n",
    "                \n",
    "            if current_step % 500 == 0:\n",
    "                samples = wgan.generate_samples(16)\n",
    "                save_path = os.path.join(save_dir, f'wgan_epoch_{epoch}_step_{current_step}.png')\n",
    "                torchvision.utils.save_image(\n",
    "                    samples,\n",
    "                    save_path,\n",
    "                    normalize=True,\n",
    "                    nrow=4\n",
    "                )\n",
    "                print(f\"Saved generated samples to {save_path}\")\n",
    "            \n",
    "            if current_step >= 50000:\n",
    "                print(\"Reached maximum number of steps (50,000). Stopping training.\")\n",
    "                return wgan\n",
    "    \n",
    "    return wgan\n",
    "\n",
    "# First, confirm your training parameters\n",
    "print(f\"Training parameters:\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Batches per epoch: {num_batches_per_epoch}\")\n",
    "print(f\"Number of epochs: {num_of_epochs}\")\n",
    "\n",
    "# Initialize the WGAN training process\n",
    "wgan = train_wgan(\n",
    "    train_iterator=train_iterator,  # Your cycling iterator\n",
    "    num_batches_per_epoch=num_batches_per_epoch,  # From your calculation\n",
    "    num_of_epochs=num_of_epochs,  # From your calculation\n",
    "    device=device,  # Your cuda device\n",
    "    class_names=class_names  # Your CIFAR-100 class names\n",
    ")\n",
    "\n",
    "# Generate a batch of 16 samples\n",
    "samples = wgan.generate_samples(16)\n",
    "\n",
    "# Save the samples\n",
    "save_path = 'generated_samples.png'\n",
    "torchvision.utils.save_image(\n",
    "    samples,\n",
    "    save_path,\n",
    "    normalize=True,\n",
    "    nrow=4\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
