{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display as disp\n",
    "from torch.nn.utils import spectral_norm   \n",
    "from torch import optim \n",
    "import os\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device.type)\n",
    "\n",
    "# helper function to make getting another batch of data easier\n",
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for x in iterable:\n",
    "            yield x\n",
    "\n",
    "class_names = ['apple','aquarium_fish','baby','bear','beaver','bed','bee','beetle','bicycle','bottle','bowl','boy','bridge','bus','butterfly','camel','can','castle','caterpillar','cattle','chair','chimpanzee','clock','cloud','cockroach','couch','crab','crocodile','cup','dinosaur','dolphin','elephant','flatfish','forest','fox','girl','hamster','house','kangaroo','computer_keyboard','lamp','lawn_mower','leopard','lion','lizard','lobster','man','maple_tree','motorcycle','mountain','mouse','mushroom','oak_tree','orange','orchid','otter','palm_tree','pear','pickup_truck','pine_tree','plain','plate','poppy','porcupine','possum','rabbit','raccoon','ray','road','rocket','rose','sea','seal','shark','shrew','skunk','skyscraper','snail','snake','spider','squirrel','streetcar','sunflower','sweet_pepper','table','tank','telephone','television','tiger','tractor','train','trout','tulip','turtle','wardrobe','whale','willow_tree','wolf','woman','worm']\n",
    "\n",
    "# Data loading\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.CIFAR100('data', train=True, download=True, transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])),\n",
    "    batch_size=64, drop_last=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.CIFAR100('data', train=False, download=True, transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize([32,32]),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])),\n",
    "    batch_size=64, drop_last=True)\n",
    "\n",
    "train_iterator = iter(cycle(train_loader))\n",
    "test_iterator = iter(cycle(test_loader))\n",
    "\n",
    "# Calculate training parameters\n",
    "batch_size = 64\n",
    "num_batches_per_epoch = len(train_loader.dataset) // batch_size\n",
    "num_of_epochs = 50000 // num_batches_per_epoch\n",
    "LATENT_DIM = 128\n",
    "NUM_CLASSES = 100\n",
    "\n",
    "print(f'> Size of training dataset {len(train_loader.dataset)}')\n",
    "print(f'> Size of test dataset {len(test_loader.dataset)}')\n",
    "print(\"Number of classes: \", len(class_names))\n",
    "print(\"Number of batches per epoch: \", num_batches_per_epoch)\n",
    "print(\"Number of epochs: \", num_of_epochs)\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = spectral_norm(nn.Conv2d(in_channels, in_channels, 3, padding=1))\n",
    "        self.conv2 = spectral_norm(nn.Conv2d(in_channels, in_channels, 3, padding=1))\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        return F.relu(x + residual)\n",
    "\n",
    "class CVAE(nn.Module):\n",
    "    def __init__(self, latent_dim=LATENT_DIM, num_classes=NUM_CLASSES):\n",
    "        super(CVAE, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc_conv1 = spectral_norm(nn.Conv2d(3, 64, 3, stride=2, padding=1))  # 16x16\n",
    "        self.enc_res1 = ResBlock(64)\n",
    "        self.enc_conv2 = spectral_norm(nn.Conv2d(64, 128, 3, stride=2, padding=1))  # 8x8\n",
    "        self.enc_res2 = ResBlock(128)\n",
    "        self.enc_conv3 = spectral_norm(nn.Conv2d(128, 256, 3, stride=2, padding=1))  # 4x4\n",
    "        self.enc_res3 = ResBlock(256)\n",
    "        \n",
    "        # Class embedding\n",
    "        self.class_embedding = nn.Embedding(num_classes, 512)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.enc_fc = nn.Linear(256 * 4 * 4 + 512, 1024)\n",
    "        self.fc_mu = nn.Linear(1024, latent_dim)\n",
    "        self.fc_var = nn.Linear(1024, latent_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.dec_fc1 = nn.Linear(latent_dim + 512, 1024)\n",
    "        self.dec_fc2 = nn.Linear(1024, 256 * 4 * 4)\n",
    "        \n",
    "        self.dec_conv1 = spectral_norm(nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1))  # 8x8\n",
    "        self.dec_res1 = ResBlock(128)\n",
    "        self.dec_conv2 = spectral_norm(nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1))  # 16x16\n",
    "        self.dec_res2 = ResBlock(64)\n",
    "        self.dec_conv3 = spectral_norm(nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1))  # 32x32\n",
    "        \n",
    "    def encode(self, x):\n",
    "        # Encode image\n",
    "        x = F.relu(self.enc_conv1(x))\n",
    "        x = self.enc_res1(x)\n",
    "        x = F.relu(self.enc_conv2(x))\n",
    "        x = self.enc_res2(x)\n",
    "        x = F.relu(self.enc_conv3(x))\n",
    "        x = self.enc_res3(x)\n",
    "        x = x.view(-1, 256 * 4 * 4)\n",
    "        \n",
    "        # Process class label\n",
    "        c_emb = self.class_embedding(c)\n",
    "        \n",
    "        # Combine image and class features\n",
    "        x = torch.cat([x, c_emb], dim=1)\n",
    "        x = F.relu(self.enc_fc(x))\n",
    "        \n",
    "        mu = self.fc_mu(x)\n",
    "        log_var = self.fc_var(x)\n",
    "        return mu, log_var\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        # Process class label\n",
    "        c_emb = self.class_embedding(c)\n",
    "        \n",
    "        # Combine latent and class features\n",
    "        z = torch.cat([z, c_emb], dim=1)\n",
    "        \n",
    "        x = F.relu(self.dec_fc1(z))\n",
    "        x = F.relu(self.dec_fc2(x))\n",
    "        x = x.view(-1, 256, 4, 4)\n",
    "        \n",
    "        x = F.relu(self.dec_conv1(x))\n",
    "        x = self.dec_res1(x)\n",
    "        x = F.relu(self.dec_conv2(x))\n",
    "        x = self.dec_res2(x)\n",
    "        x = torch.tanh(self.dec_conv3(x))\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x, c)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        return self.decode(z, c), mu, log_var\n",
    "\n",
    "def loss_function(recon_x, x, mu, log_var, beta=4.0):\n",
    "    # Reconstruction loss (MSE for images)\n",
    "    MSE = F.mse_loss(recon_x, x, reduction='sum')\n",
    "    \n",
    "    # KL divergence loss with increased weight (beta-VAE)\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    \n",
    "    return MSE + beta * KLD\n",
    "\n",
    "def show_images(images, labels=None, title=\"Generated Images\"):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.title(title)\n",
    "    \n",
    "    # Create a grid of subplots\n",
    "    grid_size = int(np.ceil(np.sqrt(len(images))))\n",
    "    \n",
    "    for i, img in enumerate(images):\n",
    "        plt.subplot(grid_size, grid_size, i + 1)\n",
    "        # Move the image to CPU and convert to numpy\n",
    "        if torch.is_tensor(img):\n",
    "            img = img.detach().cpu()\n",
    "        # Rearrange from (C,H,W) to (H,W,C)\n",
    "        img = img.permute(1, 2, 0).numpy()\n",
    "        # Clip values to valid range\n",
    "        img = np.clip(img, 0, 1)\n",
    "        plt.imshow(img)\n",
    "        if labels is not None:\n",
    "            plt.title(class_names[labels[i]], fontsize=8)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    disp.clear_output(wait=True)\n",
    "    disp.display(plt.gcf())\n",
    "    plt.close()\n",
    "\n",
    "def generate_and_show_images(model, epoch, num_images=16):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Generate specific classes\n",
    "        selected_classes = np.random.choice(NUM_CLASSES, num_images)\n",
    "        class_labels = torch.tensor(selected_classes).to(device)\n",
    "        \n",
    "        # Sample from standard normal distribution\n",
    "        z = torch.randn(num_images, LATENT_DIM).to(device)\n",
    "        \n",
    "        # Generate images\n",
    "        samples = model.decode(z)\n",
    "        # Denormalize\n",
    "        samples = samples * 0.5 + 0.5\n",
    "        \n",
    "        # Show images with class labels\n",
    "        show_images(samples, selected_classes, f'Generated Images - Epoch {epoch}')\n",
    "    \n",
    "    return samples\n",
    "\n",
    "\n",
    "def train_model():\n",
    "    model = VAE().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    steps = 0\n",
    "    epoch = 0\n",
    "    \n",
    "    while steps < 50000:\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for batch_idx in range(num_batches_per_epoch):\n",
    "            data, _ = next(train_iterator)\n",
    "            data = data.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, mu, log_var = model(data)\n",
    "            loss = loss_function(recon_batch, data, mu, log_var)\n",
    "            \n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            \n",
    "            steps += 1\n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f'Epoch: {epoch}, Batch: {batch_idx}, Step: {steps}, Loss: {loss.item() / len(data):.4f}')\n",
    "                \n",
    "            if steps >= 50000:\n",
    "                break\n",
    "        \n",
    "        avg_loss = train_loss / len(train_loader.dataset)\n",
    "        print(f'====> Epoch: {epoch} Average loss: {avg_loss:.4f}')\n",
    "\n",
    "        generate_and_show_images(model, epoch)\n",
    "\n",
    "        epoch += 1\n",
    "    \n",
    "    return model\n",
    "\n",
    "def generate_images(model, num_images=16):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Sample from standard normal distribution\n",
    "        z = torch.randn(num_images, LATENT_DIM).to(device)\n",
    "        # Generate images\n",
    "        sample = model.decode(z)\n",
    "        # Denormalize\n",
    "        sample = sample * 0.5 + 0.5\n",
    "        \n",
    "    return sample\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Train the model\n",
    "    model = train_model()\n",
    "    \n",
    "    # Generate some sample images\n",
    "    samples = generate_images(model)\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), 'cifar100_vae.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
