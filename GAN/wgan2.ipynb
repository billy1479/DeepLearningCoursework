{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display as disp\n",
    "from torch.nn.utils import spectral_norm    \n",
    "from torch import optim;\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to make getting another batch of data easier\n",
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for x in iterable:\n",
    "            yield x\n",
    "\n",
    "class_names = ['apple','aquarium_fish','baby','bear','beaver','bed','bee','beetle','bicycle','bottle','bowl','boy','bridge','bus','butterfly','camel','can','castle','caterpillar','cattle','chair','chimpanzee','clock','cloud','cockroach','couch','crab','crocodile','cup','dinosaur','dolphin','elephant','flatfish','forest','fox','girl','hamster','house','kangaroo','computer_keyboard','lamp','lawn_mower','leopard','lion','lizard','lobster','man','maple_tree','motorcycle','mountain','mouse','mushroom','oak_tree','orange','orchid','otter','palm_tree','pear','pickup_truck','pine_tree','plain','plate','poppy','porcupine','possum','rabbit','raccoon','ray','road','rocket','rose','sea','seal','shark','shrew','skunk','skyscraper','snail','snake','spider','squirrel','streetcar','sunflower','sweet_pepper','table','tank','telephone','television','tiger','tractor','train','trout','tulip','turtle','wardrobe','whale','willow_tree','wolf','woman','worm',]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.CIFAR100('data', train=True, download=True, transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])),\n",
    "    batch_size=32, drop_last=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.CIFAR100('data', train=False, download=True, transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize([32,32]),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])),\n",
    "    batch_size=32, drop_last=True)\n",
    "\n",
    "train_iterator = iter(cycle(train_loader))\n",
    "test_iterator = iter(cycle(test_loader))\n",
    "\n",
    "print(f'> Size of training dataset {len(train_loader.dataset)}')\n",
    "print(f'> Size of test dataset {len(test_loader.dataset)}')\n",
    "print(\"Number of classes: \", len(class_names))\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "num_batches_per_epoch = len(train_loader.dataset) // batch_size\n",
    "\n",
    "num_of_epochs = 50000 // num_batches_per_epoch\n",
    "\n",
    "print(\"Number of batches per epoch: \", num_batches_per_epoch)\n",
    "print(\"Number of epochs: \", num_of_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=100):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # Initial size before upsampling: 4x4\n",
    "        self.init_size = 4\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Linear layer to reshape noise into initial feature maps\n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256 * self.init_size ** 2)\n",
    "        )\n",
    "        \n",
    "        # Complex convolutional structure for generating high-quality color images\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            # First block: 4x4 -> 8x8\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(256, 256, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # Second block: 8x8 -> 16x16\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(256, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # Third block: 16x16 -> 32x32\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # Final layer: output 3 channels for RGB\n",
    "            nn.Conv2d(64, 3, 3, stride=1, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        # Transform noise into initial feature space\n",
    "        out = self.l1(z)\n",
    "        # Reshape into feature maps\n",
    "        out = out.view(out.shape[0], 256, self.init_size, self.init_size)\n",
    "        # Generate image through convolutional blocks\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        # Convolutional feature extraction\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            # Input layer: 32x32x3\n",
    "            nn.Conv2d(3, 64, 4, stride=2, padding=1),  # -> 16x16x64\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),  # -> 8x8x128\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.BatchNorm2d(128),\n",
    "            \n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),  # -> 4x4x256\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.BatchNorm2d(256),\n",
    "            \n",
    "            nn.Conv2d(256, 512, 4, stride=2, padding=1),  # -> 2x2x512\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.BatchNorm2d(512),\n",
    "        )\n",
    "        \n",
    "        # Fully connected layer for final decision\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 * 2 * 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        features = self.conv_blocks(img)\n",
    "        features = features.view(features.shape[0], -1)\n",
    "        validity = self.fc(features)\n",
    "        return validity\n",
    "\n",
    "class WGAN:\n",
    "    def __init__(self, latent_dim=100, clip_value=0.01, n_critic=5, device='cuda'):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.clip_value = clip_value\n",
    "        self.n_critic = n_critic\n",
    "        self.device = device\n",
    "        \n",
    "        # Initialize generator and critic\n",
    "        self.generator = Generator(latent_dim).to(device)\n",
    "        self.critic = Critic().to(device)\n",
    "        \n",
    "        # Initialize optimizers with learning rates from WGAN paper\n",
    "        self.optimizer_G = optim.RMSprop(self.generator.parameters(), lr=0.00005)\n",
    "        self.optimizer_C = optim.RMSprop(self.critic.parameters(), lr=0.00005)\n",
    "        \n",
    "        # Initialize training step counter\n",
    "        self.steps = 0\n",
    "        \n",
    "        # Lists to store losses for plotting\n",
    "        self.G_losses = []\n",
    "        self.C_losses = []\n",
    "\n",
    "    def train_step(self, real_imgs):\n",
    "        batch_size = real_imgs.shape[0]\n",
    "        real_imgs = real_imgs.to(self.device)\n",
    "        \n",
    "        # ---------------------\n",
    "        #  Train Critic\n",
    "        # ---------------------\n",
    "        self.optimizer_C.zero_grad()\n",
    "        \n",
    "        # Sample noise for generator input\n",
    "        z = torch.randn(batch_size, self.latent_dim).to(self.device)\n",
    "        \n",
    "        # Generate fake images\n",
    "        fake_imgs = self.generator(z).detach()\n",
    "        \n",
    "        # Compute Wasserstein distance\n",
    "        real_validity = self.critic(real_imgs)\n",
    "        fake_validity = self.critic(fake_imgs)\n",
    "        \n",
    "        # Critic loss\n",
    "        critic_loss = -torch.mean(real_validity) + torch.mean(fake_validity)\n",
    "        \n",
    "        # Update critic\n",
    "        critic_loss.backward()\n",
    "        self.optimizer_C.step()\n",
    "        \n",
    "        # Clip critic weights\n",
    "        for p in self.critic.parameters():\n",
    "            p.data.clamp_(-self.clip_value, self.clip_value)\n",
    "        \n",
    "        # Store critic loss\n",
    "        self.C_losses.append(critic_loss.item())\n",
    "        \n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "        if self.steps % self.n_critic == 0:\n",
    "            self.optimizer_G.zero_grad()\n",
    "            \n",
    "            # Generate images\n",
    "            gen_imgs = self.generator(z)\n",
    "            \n",
    "            # Generator loss\n",
    "            gen_validity = self.critic(gen_imgs)\n",
    "            generator_loss = -torch.mean(gen_validity)\n",
    "            \n",
    "            # Update generator\n",
    "            generator_loss.backward()\n",
    "            self.optimizer_G.step()\n",
    "            \n",
    "            # Store generator loss\n",
    "            self.G_losses.append(generator_loss.item())\n",
    "            \n",
    "            return generator_loss.item(), critic_loss.item()\n",
    "        \n",
    "        self.steps += 1\n",
    "        return None, critic_loss.item()\n",
    "\n",
    "    def generate_samples(self, n_samples):\n",
    "        self.generator.eval()\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(n_samples, self.latent_dim).to(self.device)\n",
    "            samples = self.generator(z)\n",
    "        self.generator.train()\n",
    "        return samples\n",
    "\n",
    "# Training loop using the provided iterator structure\n",
    "def train_wgan(num_batches_per_epoch, num_of_epochs, train_iterator, device='cuda'):\n",
    "    # Initialize WGAN\n",
    "    wgan = WGAN(latent_dim=100, clip_value=0.01, n_critic=5, device=device)\n",
    "\n",
    "    print(\"params: \", sum(p.numel() for p in wgan.generator.parameters()))\n",
    "    \n",
    "    total_steps = num_batches_per_epoch * num_of_epochs\n",
    "    \n",
    "    for step in range(total_steps):\n",
    "        # Get batch of real images\n",
    "        real_imgs, _ = next(train_iterator)\n",
    "        \n",
    "        # Train for one step\n",
    "        g_loss, c_loss = wgan.train_step(real_imgs)\n",
    "        \n",
    "        # Print progress\n",
    "        if step % 100 == 0:\n",
    "            epoch = step // num_batches_per_epoch\n",
    "            batch = step % num_batches_per_epoch\n",
    "            print(f\"[Epoch {epoch}/{num_of_epochs}] \"\n",
    "                  f\"[Batch {batch}/{num_batches_per_epoch}] \"\n",
    "                  f\"[C loss: {c_loss:.4f}] \"\n",
    "                  + (f\"[G loss: {g_loss:.4f}]\" if g_loss is not None else \"\"))\n",
    "            \n",
    "            # Generate and save sample images\n",
    "            if step % 500 == 0:\n",
    "                samples = wgan.generate_samples(16)\n",
    "                torchvision.utils.save_image(samples,\n",
    "                                           f'generated_images/wgan_step_{step}.png',\n",
    "                                           normalize=True,\n",
    "                                           nrow=4)\n",
    "    \n",
    "    return wgan\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "wgan = train_wgan(num_batches_per_epoch, num_of_epochs, train_iterator, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
