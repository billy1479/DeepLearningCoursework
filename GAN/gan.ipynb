{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display as disp\n",
    "from torch.nn.utils import spectral_norm    \n",
    "from torch import optim;\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to make getting another batch of data easier\n",
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for x in iterable:\n",
    "            yield x\n",
    "\n",
    "class_names = ['apple','aquarium_fish','baby','bear','beaver','bed','bee','beetle','bicycle','bottle','bowl','boy','bridge','bus','butterfly','camel','can','castle','caterpillar','cattle','chair','chimpanzee','clock','cloud','cockroach','couch','crab','crocodile','cup','dinosaur','dolphin','elephant','flatfish','forest','fox','girl','hamster','house','kangaroo','computer_keyboard','lamp','lawn_mower','leopard','lion','lizard','lobster','man','maple_tree','motorcycle','mountain','mouse','mushroom','oak_tree','orange','orchid','otter','palm_tree','pear','pickup_truck','pine_tree','plain','plate','poppy','porcupine','possum','rabbit','raccoon','ray','road','rocket','rose','sea','seal','shark','shrew','skunk','skyscraper','snail','snake','spider','squirrel','streetcar','sunflower','sweet_pepper','table','tank','telephone','television','tiger','tractor','train','trout','tulip','turtle','wardrobe','whale','willow_tree','wolf','woman','worm',]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.CIFAR100('data', train=True, download=True, transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])),\n",
    "    batch_size=32, drop_last=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.CIFAR100('data', train=False, download=True, transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize([32,32]),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])),\n",
    "    batch_size=32, drop_last=True)\n",
    "\n",
    "train_iterator = iter(cycle(train_loader))\n",
    "test_iterator = iter(cycle(test_loader))\n",
    "\n",
    "print(f'> Size of training dataset {len(train_loader.dataset)}')\n",
    "print(f'> Size of test dataset {len(test_loader.dataset)}')\n",
    "print(\"Number of classes: \", len(class_names))\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "num_batches_per_epoch = len(train_loader.dataset) // batch_size\n",
    "\n",
    "num_of_epochs = 50000 // num_batches_per_epoch\n",
    "\n",
    "print(\"Number of batches per epoch: \", num_batches_per_epoch)\n",
    "print(\"Number of epochs: \", num_of_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's view some of the training data\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "x, t = next(train_iterator)\n",
    "\n",
    "# Ensure the tensor is correctly moved to the GPU\n",
    "x = x.to(device)\n",
    "t = t.to(device)\n",
    "\n",
    "# Plot the images\n",
    "plt.imshow(torchvision.utils.make_grid(x).cpu().numpy().transpose(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    \"\"\"ResNet-style block with skip connections and normalization\"\"\"\n",
    "    def __init__(self, channels, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = F.leaky_relu(self.bn1(self.conv1(x)), 0.2)\n",
    "        out = self.dropout(out)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += residual\n",
    "        out = F.leaky_relu(out, 0.2)\n",
    "        return out\n",
    "\n",
    "class ResNetGenerator(nn.Module):\n",
    "    \"\"\"Generator using ResNet principles for high-quality image synthesis\"\"\"\n",
    "    def __init__(self, latent_dim=100, output_channels=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 512 * 4 * 4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm1d(512 * 4 * 4)\n",
    "        )\n",
    "        \n",
    "        self.main_path = nn.Sequential(\n",
    "            # 4x4 -> 8x8\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            ResNetBlock(512),\n",
    "            \n",
    "            # 8x8 -> 16x16\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            ResNetBlock(512),\n",
    "            nn.Conv2d(512, 256, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 16x16 -> 32x32\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            ResNetBlock(256),\n",
    "            nn.Conv2d(256, 128, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # Final processing\n",
    "            ResNetBlock(128),\n",
    "            nn.Conv2d(128, output_channels, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        x = self.initial(z)\n",
    "        x = x.view(-1, 512, 4, 4)\n",
    "        return self.main_path(x)\n",
    "\n",
    "class ResNetDiscriminator(nn.Module):\n",
    "    \"\"\"Discriminator using ResNet principles for robust classification\"\"\"\n",
    "    def __init__(self, input_channels=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.main_path = nn.Sequential(\n",
    "            # Initial convolution: 32x32 -> 32x32\n",
    "            nn.Conv2d(input_channels, 64, 3, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # First block: 32x32 -> 16x16\n",
    "            ResNetBlock(64),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # Second block: 16x16 -> 8x8\n",
    "            ResNetBlock(128),\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # Third block: 8x8 -> 4x4\n",
    "            ResNetBlock(256),\n",
    "            nn.Conv2d(256, 512, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # Final block\n",
    "            ResNetBlock(512)\n",
    "        )\n",
    "        \n",
    "        self.output = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.main_path(x)\n",
    "        return self.output(features)\n",
    "\n",
    "class ResNetGAN:\n",
    "    \"\"\"Complete GAN implementation with training and visualization\"\"\"\n",
    "    def __init__(self, latent_dim=100, device='cuda'):\n",
    "        self.device = device\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Initialize networks\n",
    "        self.generator = ResNetGenerator(latent_dim).to(device)\n",
    "        self.discriminator = ResNetDiscriminator().to(device)\n",
    "        \n",
    "        # Initialize optimizers\n",
    "        self.g_optimizer = optim.Adam(self.generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        self.d_optimizer = optim.Adam(self.discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        \n",
    "        # Initialize criterion\n",
    "        self.criterion = nn.BCELoss()\n",
    "        \n",
    "        # Initialize logs\n",
    "        self.g_losses = []\n",
    "        self.d_losses = []\n",
    "    \n",
    "    def train_step(self, real_images):\n",
    "        batch_size = real_images.size(0)\n",
    "        real_label = torch.ones(batch_size, 1).to(self.device)\n",
    "        fake_label = torch.zeros(batch_size, 1).to(self.device)\n",
    "        \n",
    "        # Train Discriminator\n",
    "        self.d_optimizer.zero_grad()\n",
    "        \n",
    "        # Train on real images\n",
    "        real_output = self.discriminator(real_images)\n",
    "        d_loss_real = self.criterion(real_output, real_label)\n",
    "        \n",
    "        # Train on fake images\n",
    "        z = torch.randn(batch_size, self.latent_dim).to(self.device)\n",
    "        fake_images = self.generator(z)\n",
    "        fake_output = self.discriminator(fake_images.detach())\n",
    "        d_loss_fake = self.criterion(fake_output, fake_label)\n",
    "        \n",
    "        # Combine losses and update discriminator\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        self.d_optimizer.step()\n",
    "        \n",
    "        # Train Generator\n",
    "        self.g_optimizer.zero_grad()\n",
    "        \n",
    "        # Generate new fake images\n",
    "        z = torch.randn(batch_size, self.latent_dim).to(self.device)\n",
    "        fake_images = self.generator(z)\n",
    "        fake_output = self.discriminator(fake_images)\n",
    "        \n",
    "        # Calculate generator loss and update\n",
    "        g_loss = self.criterion(fake_output, real_label)\n",
    "        g_loss.backward()\n",
    "        self.g_optimizer.step()\n",
    "        \n",
    "        return d_loss.item(), g_loss.item()\n",
    "    \n",
    "    def generate_samples(self, num_samples=16):\n",
    "        \"\"\"Generate and display sample images\"\"\"\n",
    "        self.generator.eval()\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(num_samples, self.latent_dim).to(self.device)\n",
    "            fake_images = self.generator(z)\n",
    "            \n",
    "            # Display the generated images\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            grid_img = torchvision.utils.make_grid(fake_images, nrow=4, normalize=True)\n",
    "            plt.imshow(grid_img.cpu().permute(1, 2, 0))\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "    \n",
    "    def visualize_training(self):\n",
    "        \"\"\"Plot the training losses\"\"\"\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(self.g_losses, label='Generator Loss')\n",
    "        plt.plot(self.d_losses, label='Discriminator Loss')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "# Training loop\n",
    "def train_gan(gan, train_loader, num_epochs):\n",
    "    print(\"Starting GAN training...\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (real_images, _) in enumerate(train_loader):\n",
    "            real_images = real_images.to(gan.device)\n",
    "            \n",
    "            # Train for one batch\n",
    "            d_loss, g_loss = gan.train_step(real_images)\n",
    "            \n",
    "            # Store losses\n",
    "            gan.d_losses.append(d_loss)\n",
    "            gan.g_losses.append(g_loss)\n",
    "            \n",
    "        # Print progress and show samples\n",
    "        if (epoch + 1) % 1 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "            print(f'D_loss: {d_loss:.4f}, G_loss: {g_loss:.4f}')\n",
    "            gan.generate_samples()\n",
    "            gan.visualize_training()\n",
    "\n",
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Initialize GAN\n",
    "    gan = ResNetGAN(device=device)\n",
    "\n",
    "    print(\"Parameters of generator: \", sum(p.numel() for p in gan.generator.parameters() if p.requires_grad))\n",
    "    \n",
    "    # Train GAN using your train_loader\n",
    "    train_gan(gan, train_loader, num_of_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
