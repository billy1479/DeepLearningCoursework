{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Practical Answers - Getting the Best Performance out of a Neural Network\n",
        "---\n",
        "\n",
        "## Author : Amir Atapour-Abarghouei, amir.atapour-abarghouei@durham.ac.uk\n",
        "\n",
        "This notebook will provide you with the answer to the excercise for improved design and training of a nerual network. Try to solve the problems yourself before looking at the answers.\n",
        "\n",
        "Copyright (c) 2024 Amir Atapour-Abarghouei, UK.\n",
        "\n",
        "License : LGPL - http://www.gnu.org/licenses/lgpl.html"
      ],
      "metadata": {
        "id": "wH0qUaQrkh8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this practical, we will be using [Caltech 101](https://data.caltech.edu/records/mzrjq-6wc02). The dataset consistes of objects belonging to 101 categories with about 40 to 800 images per category. This dataset is generally considered to be challenging.\n",
        "\n",
        "First, let's import what we need and set Torch to use the GPU:"
      ],
      "metadata": {
        "id": "zO8-xg0JlAZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "device = torch.device('cuda')\n",
        "print('donso!')"
      ],
      "metadata": {
        "id": "GOztfpi3mgo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to load the data. Write the code needed to download the dataset and setup the data loaders. The dataset is available in Torchvision:\n",
        "\n",
        "https://pytorch.org/vision/main/generated/torchvision.datasets.Caltech101.html"
      ],
      "metadata": {
        "id": "T_SGT0CMnETx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we want to load the model. We will use off-the-shelf architectures in torchvision.\n",
        "\n",
        "https://pytorch.org/vision/stable/models.html\n",
        "\n",
        "Let's start with ResNet18, which is a good starting point, but you should load different ones and try to experiment to see which gives the best results. The answer for ResNet18 is provided. Once you know how to do this, it should be easy to apply this to lots of different models."
      ],
      "metadata": {
        "id": "UPFyV164whaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model\n",
        "class ResNet18Modified(nn.Module):\n",
        "    def __init__(self, num_classes=102):\n",
        "        super(ResNet18Modified, self).__init__()\n",
        "        # Load the ResNet18 model without pre-trained weights\n",
        "        self.model = torchvision.models.resnet18()\n",
        "        # Modify the final fully connected layer to match the number of classes\n",
        "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# create the modified ResNet18 model\n",
        "N = ResNet18Modified(num_classes=102).to(device)\n",
        "\n",
        "# number of model parameters\n",
        "print(f'Number of model parameters is: {len(torch.nn.utils.parameters_to_vector(N.parameters()))}')\n",
        "\n",
        "# initialize the optimiser\n",
        "optimiser = torch.optim.Adam(N.parameters(), lr=0.001)\n",
        "epoch = 0"
      ],
      "metadata": {
        "id": "DCB-eLEryIgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's train the model:"
      ],
      "metadata": {
        "id": "WpGFF-AQy869"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define transformations for augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    # resize all images to 128x128\n",
        "    transforms.Resize((128, 128)),\n",
        "    # random flipping\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    # all images are RGB\n",
        "    transforms.Lambda(lambda x: x.convert(\"RGB\")),\n",
        "    # randomly rotate images up to 45 degrees\n",
        "    transforms.RandomRotation(45),\n",
        "    # color jitter\n",
        "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n",
        "    # affine transformations with shear\n",
        "    transforms.RandomAffine(degrees=30, shear=15),\n",
        "    # convert some images to grayscale\n",
        "    transforms.RandomGrayscale(p=0.3),\n",
        "    # Gaussian blur\n",
        "    transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0)),\n",
        "    # perspective transformation\n",
        "    transforms.RandomPerspective(distortion_scale=0.5, p=0.5),\n",
        "    # randomly invert colors\n",
        "    transforms.RandomInvert(p=0.2),\n",
        "    # adjust contrast\n",
        "    transforms.RandomAutocontrast(p=0.3),\n",
        "    # randomly adjust sharpness\n",
        "    transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.2),\n",
        "    # convert to tensor\n",
        "    transforms.ToTensor(),\n",
        "    # randomly erase parts of the image\n",
        "    transforms.RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.3, 3.3)),\n",
        "])\n",
        "\n",
        "# for the test set, only resize, convert to tensor\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.Lambda(lambda x: x.convert(\"RGB\")),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# load the full dataset\n",
        "full_dataset = datasets.Caltech101(root='data', download=True, transform=train_transform, target_type='category')\n",
        "\n",
        "# define the train-test split ratio\n",
        "train_size = int(0.8 * len(full_dataset))  # 80% for training\n",
        "test_size = len(full_dataset) - train_size  # 20% for testing\n",
        "\n",
        "# split the dataset into training and testing sets\n",
        "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
        "\n",
        "# update the transformations for the test dataset\n",
        "test_dataset.dataset.transform = test_transform\n",
        "\n",
        "# create DataLoaders for the training and test sets\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, drop_last=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "# print dataset sizes\n",
        "print(f\"There are {len(train_dataset)} images in the training set!\")\n",
        "print(f\"There are {len(test_dataset)} images in the test set!\")"
      ],
      "metadata": {
        "id": "2lK9E7yloiQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the total number of training steps\n",
        "total_steps = 500\n",
        "step = 0\n",
        "\n",
        "# training mode\n",
        "N.train()\n",
        "\n",
        "# arrays for metrics\n",
        "train_loss_arr = np.zeros(0)\n",
        "train_acc_arr = np.zeros(0)\n",
        "test_acc_arr = np.zeros(0)\n",
        "\n",
        "# loop until the total number of steps is reached\n",
        "while step < total_steps:\n",
        "    for i, batch in enumerate(train_loader):\n",
        "        if step >= total_steps:\n",
        "            # stop if we've reached the total number of steps\n",
        "            break\n",
        "\n",
        "        # sample x from the dataset\n",
        "        x, t = batch\n",
        "        x, t = x.to(device), t.to(device)\n",
        "\n",
        "        optimiser.zero_grad()\n",
        "        p = N(x)\n",
        "        pred = p.argmax(dim=1, keepdim=True)\n",
        "        loss = torch.nn.functional.cross_entropy(p, t)\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "\n",
        "        train_loss_arr = np.append(train_loss_arr, loss.cpu().data)\n",
        "        train_acc_arr = np.append(train_acc_arr, pred.data.eq(t.view_as(pred)).float().mean().item())\n",
        "\n",
        "        # increment the step counter\n",
        "        step += 1\n",
        "\n",
        "        # print progress every given number of steps\n",
        "        if step % 50 == 0:\n",
        "            print(f'Step {step}: train loss: {train_loss_arr.mean():.3f}, train acc: {train_acc_arr.mean():.3f}')\n",
        "            train_loss_arr = np.zeros(0)\n",
        "            train_acc_arr = np.zeros(0)\n",
        "\n",
        "# evaluation phase\n",
        "N.eval()\n",
        "\n",
        "# disable gradient computation\n",
        "with torch.no_grad():\n",
        "    for x, t in test_loader:\n",
        "        x, t = x.to(device), t.to(device)\n",
        "        p = N(x)\n",
        "        pred = p.argmax(dim=1, keepdim=True)\n",
        "        test_acc_arr = np.append(test_acc_arr, pred.data.eq(t.view_as(pred)).float().mean().item())\n",
        "\n",
        "print(f'* Test Accuracy : {test_acc_arr.mean():.3f}')"
      ],
      "metadata": {
        "id": "-7F9gyCJy_d2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we want to play around with finetuning - let's implement the ability to freeze a number of layers and train others."
      ],
      "metadata": {
        "id": "y0XOGEkQ6KP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model\n",
        "class ResNet18Modified(nn.Module):\n",
        "    def __init__(self, num_classes=102):\n",
        "        super(ResNet18Modified, self).__init__()\n",
        "        # load the ResNet18 model with pre-trained weights\n",
        "        self.model = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n",
        "        # modify the final fully connected layer to match the number of classes\n",
        "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "def freeze_layers(model, num_layers_to_freeze):\n",
        "    # get the layers in the model\n",
        "    layers = list(model.model.children())\n",
        "    # freeze the first num_layers_to_freeze layers\n",
        "    for layer in layers[:num_layers_to_freeze]:\n",
        "        for param in layer.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# create the modified ResNet18 model\n",
        "N = ResNet18Modified(num_classes=102).to(device)\n",
        "\n",
        "# number of layers to freeze (e.g., freeze the first 6 layers) - change this number to see what effect this might have:\n",
        "num_layers_to_freeze = 6\n",
        "\n",
        "freeze_layers(N, num_layers_to_freeze)\n",
        "\n",
        "# Print the number of model parameters\n",
        "print(f'Number of model parameters is: {len(torch.nn.utils.parameters_to_vector(N.parameters()))}')\n",
        "\n",
        "# Initialize the optimizer (only train the layers that have requires_grad = True)\n",
        "optimiser = torch.optim.Adam(filter(lambda p: p.requires_grad, N.parameters()), lr=0.001)\n",
        "epoch = 0"
      ],
      "metadata": {
        "id": "F_UbkEH4w5_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "and let's train again:"
      ],
      "metadata": {
        "id": "Kg6qj52S8G46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the total number of training steps\n",
        "total_steps = 500\n",
        "step = 0\n",
        "\n",
        "# training mode\n",
        "N.train()\n",
        "\n",
        "# arrays for metrics\n",
        "train_loss_arr = np.zeros(0)\n",
        "train_acc_arr = np.zeros(0)\n",
        "test_acc_arr = np.zeros(0)\n",
        "\n",
        "# loop until the total number of steps is reached\n",
        "while step < total_steps:\n",
        "    for i, batch in enumerate(train_loader):\n",
        "        if step >= total_steps:\n",
        "            # stop if we've reached the total number of steps\n",
        "            break\n",
        "\n",
        "        # sample x from the dataset\n",
        "        x, t = batch\n",
        "        x, t = x.to(device), t.to(device)\n",
        "\n",
        "        optimiser.zero_grad()\n",
        "        p = N(x)\n",
        "        pred = p.argmax(dim=1, keepdim=True)\n",
        "        loss = torch.nn.functional.cross_entropy(p, t)\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "\n",
        "        train_loss_arr = np.append(train_loss_arr, loss.cpu().data)\n",
        "        train_acc_arr = np.append(train_acc_arr, pred.data.eq(t.view_as(pred)).float().mean().item())\n",
        "\n",
        "        # increment the step counter\n",
        "        step += 1\n",
        "\n",
        "        # print progress every given number of steps\n",
        "        if step % 50 == 0:\n",
        "            print(f'Step {step}: train loss: {train_loss_arr.mean():.3f}, train acc: {train_acc_arr.mean():.3f}')\n",
        "            train_loss_arr = np.zeros(0)\n",
        "            train_acc_arr = np.zeros(0)\n",
        "\n",
        "# evaluation phase\n",
        "N.eval()\n",
        "\n",
        "# disable gradient computation\n",
        "with torch.no_grad():\n",
        "    for x, t in test_loader:\n",
        "        x, t = x.to(device), t.to(device)\n",
        "        p = N(x)\n",
        "        pred = p.argmax(dim=1, keepdim=True)\n",
        "        test_acc_arr = np.append(test_acc_arr, pred.data.eq(t.view_as(pred)).float().mean().item())\n",
        "\n",
        "print(f'* Test Accuracy : {test_acc_arr.mean():.3f}')"
      ],
      "metadata": {
        "id": "bAHDv61q8Iwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is important to understand how albation studies work.\n",
        "\n",
        "We have gotten very good performance because of the things we have done but because we have done lots of things, we need to understand what exactly helped us and by how much in a rigorous scientific manner.\n",
        "\n",
        "In an ablation study, individual components of the model or the training setup (e.g., layers, types of regularization, data augmentation techniques) are removed or modified to observe their impact on the overall performance.\n",
        "\n",
        "https://en.wikipedia.org/wiki/Ablation_(artificial_intelligence)\n",
        "\n",
        "Consider this for your coursework."
      ],
      "metadata": {
        "id": "HDMKD43SDYTn"
      }
    }
  ]
}