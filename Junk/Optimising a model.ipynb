{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH0qUaQrkh8I"
      },
      "source": [
        "# Deep Learning Practical Answers - Getting the Best Performance out of a Neural Network\n",
        "---\n",
        "\n",
        "## Author : Amir Atapour-Abarghouei, amir.atapour-abarghouei@durham.ac.uk\n",
        "\n",
        "This notebook will provide you with the answer to the excercise for improved design and training of a nerual network. Try to solve the problems yourself before looking at the answers.\n",
        "\n",
        "Copyright (c) 2024 Amir Atapour-Abarghouei, UK.\n",
        "\n",
        "License : LGPL - http://www.gnu.org/licenses/lgpl.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO8-xg0JlAZF"
      },
      "source": [
        "For this practical, we will be using [Caltech 101](https://data.caltech.edu/records/mzrjq-6wc02). The dataset consistes of objects belonging to 101 categories with about 40 to 800 images per category. This dataset is generally considered to be challenging.\n",
        "\n",
        "First, let's import what we need and set Torch to use the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GOztfpi3mgo9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "donso!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "device = torch.device('cuda')\n",
        "print('donso!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_SGT0CMnETx"
      },
      "source": [
        "Now we need to load the data. Write the code needed to download the dataset and setup the data loaders. The dataset is available in Torchvision:\n",
        "\n",
        "https://pytorch.org/vision/main/generated/torchvision.datasets.Caltech101.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPFyV164whaF"
      },
      "source": [
        "Now we want to load the model. We will use off-the-shelf architectures in torchvision.\n",
        "\n",
        "https://pytorch.org/vision/stable/models.html\n",
        "\n",
        "Let's start with ResNet18, which is a good starting point, but you should load different ones and try to experiment to see which gives the best results. The answer for ResNet18 is provided. Once you know how to do this, it should be easy to apply this to lots of different models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DCB-eLEryIgd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of model parameters is: 11228838\n"
          ]
        }
      ],
      "source": [
        "# define the model\n",
        "class ResNet18Modified(nn.Module):\n",
        "    def __init__(self, num_classes=102):\n",
        "        super(ResNet18Modified, self).__init__()\n",
        "        # Load the ResNet18 model without pre-trained weights\n",
        "        self.model = torchvision.models.resnet18()\n",
        "        # Modify the final fully connected layer to match the number of classes\n",
        "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# create the modified ResNet18 model\n",
        "N = ResNet18Modified(num_classes=102).to(device)\n",
        "\n",
        "# number of model parameters\n",
        "print(f'Number of model parameters is: {len(torch.nn.utils.parameters_to_vector(N.parameters()))}')\n",
        "\n",
        "# initialize the optimiser\n",
        "optimiser = torch.optim.Adam(N.parameters(), lr=0.001)\n",
        "epoch = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpGFF-AQy869"
      },
      "source": [
        "Now let's train the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2lK9E7yloiQB"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'transforms' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3152\\3369066194.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# define transformations for augmentation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m train_transform = transforms.Compose([\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;31m# resize all images to 128x128\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# random flipping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'transforms' is not defined"
          ]
        }
      ],
      "source": [
        "# define transformations for augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    # resize all images to 128x128\n",
        "    transforms.Resize((128, 128)),\n",
        "    # random flipping\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    # all images are RGB\n",
        "    transforms.Lambda(lambda x: x.convert(\"RGB\")),\n",
        "    # randomly rotate images up to 45 degrees\n",
        "    transforms.RandomRotation(45),\n",
        "    # color jitter\n",
        "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n",
        "    # affine transformations with shear\n",
        "    transforms.RandomAffine(degrees=30, shear=15),\n",
        "    # convert some images to grayscale\n",
        "    transforms.RandomGrayscale(p=0.3),\n",
        "    # Gaussian blur\n",
        "    transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0)),\n",
        "    # perspective transformation\n",
        "    transforms.RandomPerspective(distortion_scale=0.5, p=0.5),\n",
        "    # randomly invert colors\n",
        "    transforms.RandomInvert(p=0.2),\n",
        "    # adjust contrast\n",
        "    transforms.RandomAutocontrast(p=0.3),\n",
        "    # randomly adjust sharpness\n",
        "    transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.2),\n",
        "    # convert to tensor\n",
        "    transforms.ToTensor(),\n",
        "    # randomly erase parts of the image\n",
        "    # transforms.RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.3, 3.3)),\n",
        "])\n",
        "\n",
        "# for the test set, only resize, convert to tensor\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.Lambda(lambda x: x.convert(\"RGB\")),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# load the full dataset\n",
        "full_dataset = datasets.Caltech101(root='data', download=True, transform=train_transform, target_type='category')\n",
        "\n",
        "# define the train-test split ratio\n",
        "train_size = int(0.8 * len(full_dataset))  # 80% for training\n",
        "test_size = len(full_dataset) - train_size  # 20% for testing\n",
        "\n",
        "# split the dataset into training and testing sets\n",
        "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
        "\n",
        "# update the transformations for the test dataset\n",
        "test_dataset.dataset.transform = test_transform\n",
        "\n",
        "# create DataLoaders for the training and test sets\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, drop_last=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "# print dataset sizes\n",
        "print(f\"There are {len(train_dataset)} images in the training set!\")\n",
        "print(f\"There are {len(test_dataset)} images in the test set!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-7F9gyCJy_d2"
      },
      "outputs": [
        {
          "ename": "PicklingError",
          "evalue": "Can't pickle <function <lambda> at 0x000002222503C1F0>: attribute lookup <lambda> on __main__ failed",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_38328\\1818611165.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# loop until the total number of steps is reached\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtotal_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mtotal_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[1;31m# stop if we've reached the total number of steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Billy\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    437\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Billy\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_worker_number_rationality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Billy\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Billy\\anaconda3\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    119\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Billy\\anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Billy\\anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Billy\\anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Billy\\anaconda3\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mPicklingError\u001b[0m: Can't pickle <function <lambda> at 0x000002222503C1F0>: attribute lookup <lambda> on __main__ failed"
          ]
        }
      ],
      "source": [
        "# define the total number of training steps\n",
        "total_steps = 500\n",
        "step = 0\n",
        "\n",
        "# training mode\n",
        "N.train()\n",
        "\n",
        "# arrays for metrics\n",
        "train_loss_arr = np.zeros(0)\n",
        "train_acc_arr = np.zeros(0)\n",
        "test_acc_arr = np.zeros(0)\n",
        "\n",
        "# loop until the total number of steps is reached\n",
        "while step < total_steps:\n",
        "    for i, batch in enumerate(train_loader):\n",
        "        if step >= total_steps:\n",
        "            # stop if we've reached the total number of steps\n",
        "            break\n",
        "\n",
        "        # sample x from the dataset\n",
        "        x, t = batch\n",
        "        x, t = x.to(device), t.to(device)\n",
        "\n",
        "        optimiser.zero_grad()\n",
        "        p = N(x)\n",
        "        pred = p.argmax(dim=1, keepdim=True)\n",
        "        loss = torch.nn.functional.cross_entropy(p, t)\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "\n",
        "        train_loss_arr = np.append(train_loss_arr, loss.cpu().data)\n",
        "        train_acc_arr = np.append(train_acc_arr, pred.data.eq(t.view_as(pred)).float().mean().item())\n",
        "\n",
        "        # increment the step counter\n",
        "        step += 1\n",
        "\n",
        "        # print progress every given number of steps\n",
        "        if step % 50 == 0:\n",
        "            print(f'Step {step}: train loss: {train_loss_arr.mean():.3f}, train acc: {train_acc_arr.mean():.3f}')\n",
        "            train_loss_arr = np.zeros(0)\n",
        "            train_acc_arr = np.zeros(0)\n",
        "\n",
        "# evaluation phase\n",
        "N.eval()\n",
        "\n",
        "# disable gradient computation\n",
        "with torch.no_grad():\n",
        "    for x, t in test_loader:\n",
        "        x, t = x.to(device), t.to(device)\n",
        "        p = N(x)\n",
        "        pred = p.argmax(dim=1, keepdim=True)\n",
        "        test_acc_arr = np.append(test_acc_arr, pred.data.eq(t.view_as(pred)).float().mean().item())\n",
        "\n",
        "print(f'* Test Accuracy : {test_acc_arr.mean():.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0XOGEkQ6KP2"
      },
      "source": [
        "Now, we want to play around with finetuning - let's implement the ability to freeze a number of layers and train others."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_UbkEH4w5_I"
      },
      "outputs": [],
      "source": [
        "# define the model\n",
        "class ResNet18Modified(nn.Module):\n",
        "    def __init__(self, num_classes=102):\n",
        "        super(ResNet18Modified, self).__init__()\n",
        "        # load the ResNet18 model with pre-trained weights\n",
        "        self.model = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n",
        "        # modify the final fully connected layer to match the number of classes\n",
        "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "def freeze_layers(model, num_layers_to_freeze):\n",
        "    # get the layers in the model\n",
        "    layers = list(model.model.children())\n",
        "    # freeze the first num_layers_to_freeze layers\n",
        "    for layer in layers[:num_layers_to_freeze]:\n",
        "        for param in layer.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# create the modified ResNet18 model\n",
        "N = ResNet18Modified(num_classes=102).to(device)\n",
        "\n",
        "# number of layers to freeze (e.g., freeze the first 6 layers) - change this number to see what effect this might have:\n",
        "num_layers_to_freeze = 6\n",
        "\n",
        "freeze_layers(N, num_layers_to_freeze)\n",
        "\n",
        "# Print the number of model parameters\n",
        "print(f'Number of model parameters is: {len(torch.nn.utils.parameters_to_vector(N.parameters()))}')\n",
        "\n",
        "# Initialize the optimizer (only train the layers that have requires_grad = True)\n",
        "optimiser = torch.optim.Adam(filter(lambda p: p.requires_grad, N.parameters()), lr=0.001)\n",
        "epoch = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kg6qj52S8G46"
      },
      "source": [
        "and let's train again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAHDv61q8Iwf"
      },
      "outputs": [],
      "source": [
        "# define the total number of training steps\n",
        "total_steps = 500\n",
        "step = 0\n",
        "\n",
        "# training mode\n",
        "N.train()\n",
        "\n",
        "# arrays for metrics\n",
        "train_loss_arr = np.zeros(0)\n",
        "train_acc_arr = np.zeros(0)\n",
        "test_acc_arr = np.zeros(0)\n",
        "\n",
        "# loop until the total number of steps is reached\n",
        "while step < total_steps:\n",
        "    for i, batch in enumerate(train_loader):\n",
        "        if step >= total_steps:\n",
        "            # stop if we've reached the total number of steps\n",
        "            break\n",
        "\n",
        "        # sample x from the dataset\n",
        "        x, t = batch\n",
        "        x, t = x.to(device), t.to(device)\n",
        "\n",
        "        optimiser.zero_grad()\n",
        "        p = N(x)\n",
        "        pred = p.argmax(dim=1, keepdim=True)\n",
        "        loss = torch.nn.functional.cross_entropy(p, t)\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "\n",
        "        train_loss_arr = np.append(train_loss_arr, loss.cpu().data)\n",
        "        train_acc_arr = np.append(train_acc_arr, pred.data.eq(t.view_as(pred)).float().mean().item())\n",
        "\n",
        "        # increment the step counter\n",
        "        step += 1\n",
        "\n",
        "        # print progress every given number of steps\n",
        "        if step % 50 == 0:\n",
        "            print(f'Step {step}: train loss: {train_loss_arr.mean():.3f}, train acc: {train_acc_arr.mean():.3f}')\n",
        "            train_loss_arr = np.zeros(0)\n",
        "            train_acc_arr = np.zeros(0)\n",
        "\n",
        "# evaluation phase\n",
        "N.eval()\n",
        "\n",
        "# disable gradient computation\n",
        "with torch.no_grad():\n",
        "    for x, t in test_loader:\n",
        "        x, t = x.to(device), t.to(device)\n",
        "        p = N(x)\n",
        "        pred = p.argmax(dim=1, keepdim=True)\n",
        "        test_acc_arr = np.append(test_acc_arr, pred.data.eq(t.view_as(pred)).float().mean().item())\n",
        "\n",
        "print(f'* Test Accuracy : {test_acc_arr.mean():.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDMKD43SDYTn"
      },
      "source": [
        "It is important to understand how albation studies work.\n",
        "\n",
        "We have gotten very good performance because of the things we have done but because we have done lots of things, we need to understand what exactly helped us and by how much in a rigorous scientific manner.\n",
        "\n",
        "In an ablation study, individual components of the model or the training setup (e.g., layers, types of regularization, data augmentation techniques) are removed or modified to observe their impact on the overall performance.\n",
        "\n",
        "https://en.wikipedia.org/wiki/Ablation_(artificial_intelligence)\n",
        "\n",
        "Consider this for your coursework."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
