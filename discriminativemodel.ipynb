{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6N22Uz-kLiZW"
   },
   "source": [
    "**Main imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MK1Jl7nkLnPA",
    "outputId": "140fac74-15b2-4d66-ea7c-ea799d544617"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "import numpy\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display as disp\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('Imports complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run1dh_hM0oO"
   },
   "source": [
    "**Download dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IAdqSy7nIFLq",
    "outputId": "09795199-1a1c-4767-b1e6-558c7f407755"
   },
   "outputs": [],
   "source": [
    "# URL of the file\n",
    "url = 'https://data.ncl.ac.uk/ndownloader/articles/24574354/versions/1'\n",
    "\n",
    "# make directory if it doesn't exist\n",
    "directory = 'classification-data'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# where to save the downloaded file\n",
    "file_path = os.path.join(directory, 'downloaded_file.zip')\n",
    "\n",
    "# send a GET request to the URL with stream=True for chunked download\n",
    "response = requests.get(url, stream=True)\n",
    "\n",
    "# check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # total size in bytes from the header\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "\n",
    "    # progress bar\n",
    "    with open(file_path, 'wb') as file, tqdm(\n",
    "            desc=\"Downloading\",\n",
    "            total=total_size,\n",
    "            unit='B',\n",
    "            unit_scale=True,\n",
    "            unit_divisor=1024,\n",
    "    ) as progress_bar:\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                file.write(chunk)\n",
    "                progress_bar.update(len(chunk))\n",
    "\n",
    "    print(\"File downloaded successfully!\")\n",
    "\n",
    "    # unzipping\n",
    "    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(directory)\n",
    "        print(f\"Files unzipped successfully in the '{directory}' directory!\")\n",
    "\n",
    "    # remove the zip file after extraction\n",
    "    os.remove(file_path)\n",
    "    print(\"Zip file removed after extraction.\")\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to download the file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation for modules - Introduced to increas accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    \n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.Lambda(lambda x: x.convert(\"RGB\")),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3sLAPCRM6_h"
   },
   "source": [
    "**Import dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bK383zeDM4Ac",
    "outputId": "b6597294-6f1d-4372-8c51-f08072bc78ab"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# directory where the data is stored\n",
    "data_dir = 'classification-data'\n",
    "\n",
    "# the .npy files\n",
    "train_x_path = os.path.join(data_dir, 'train_x.npy')\n",
    "train_y_path = os.path.join(data_dir, 'train_y.npy')\n",
    "valid_x_path = os.path.join(data_dir, 'valid_x.npy')\n",
    "valid_y_path = os.path.join(data_dir, 'valid_y.npy')\n",
    "test_x_path = os.path.join(data_dir, 'test_x.npy')\n",
    "test_y_path = os.path.join(data_dir, 'test_y.npy')\n",
    "\n",
    "# load the data\n",
    "print(\"Loading data...\")\n",
    "train_x = numpy.load(train_x_path)\n",
    "train_y = numpy.load(train_y_path)\n",
    "valid_x = numpy.load(valid_x_path)\n",
    "valid_y = numpy.load(valid_y_path)\n",
    "test_x = numpy.load(test_x_path)\n",
    "test_y = numpy.load(test_y_path)\n",
    "print(\"Data loaded successfully.\")\n",
    "\n",
    "print(\"Shape of one training sample:\", train_x.shape[1:])\n",
    "print(\"Shape of one validation sample:\", valid_x.shape[1:])\n",
    "print(\"Shape of one test sample:\", test_x.shape[1:])\n",
    "\n",
    "train_x = train_x.reshape(-1, 3, 28, 28) \n",
    "valid_x = valid_x.reshape(-1, 3, 28, 28) \n",
    "test_x = test_x.reshape(-1, 3, 28, 28)\n",
    "\n",
    "print(\"Shape of one training sample:\", train_x.shape[1:])\n",
    "print(\"Shape of one validation sample:\", valid_x.shape[1:])\n",
    "print(\"Shape of one test sample:\", test_x.shape[1:])\n",
    "\n",
    "# TRANSFORMATIONS FOR THE IMAGES - part of attempt 3+\n",
    "transform = transforms.Compose({\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((28,28))\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    # transforms.RandomInvert(p=0.2),\n",
    "    # transforms.RandomAutocontrast(p=0.3)\n",
    "})\n",
    "\n",
    "# This doesn't work\n",
    "\n",
    "train_x_transformed = torch.stack([transform(img) for img in train_x])\n",
    "train_y_transformed = torch.stack([transform(img) for img in train_y])\n",
    "\n",
    "# convert NumPy arrays to PyTorch tensors - HAS BEEN CHANGED FOR THE ABOVE\n",
    "train_x = torch.from_numpy(train_x_transformed).float()\n",
    "train_y = torch.from_numpy(train_y_transformed).long()\n",
    "valid_x = torch.from_numpy(valid_x).float()\n",
    "valid_y = torch.from_numpy(valid_y).long()\n",
    "test_x = torch.from_numpy(test_x).float()\n",
    "test_y = torch.from_numpy(test_y).long()\n",
    "\n",
    "# create TensorDataset instances\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "valid_dataset = TensorDataset(valid_x, valid_y)\n",
    "test_dataset = TensorDataset(test_x, test_y)\n",
    "\n",
    "# batch size\n",
    "batch_size = 64\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "# Helper function to cycle through the data indefinitely\n",
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for x in iterable:\n",
    "            yield x\n",
    "\n",
    "# iterators for training, validation, and test loaders\n",
    "train_iterator = iter(cycle(train_loader))\n",
    "valid_iterator = iter(cycle(valid_loader))\n",
    "test_iterator = iter(cycle(test_loader))\n",
    "\n",
    "# class names\n",
    "class_names = [str(i) for i in range(20)]\n",
    "\n",
    "# dataset sizes\n",
    "print(f'> Size of training dataset: {len(train_dataset)}')\n",
    "print(f'> Size of validation dataset: {len(valid_dataset)}')\n",
    "print(f'> Size of test dataset: {len(test_dataset)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-FdW5HnimG2"
   },
   "source": [
    "**View some of the test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 583
    },
    "id": "BtJs-qxHRLXz",
    "outputId": "9e93788b-f953-48a6-b4b4-a64eb385563c"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 70\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    img = test_loader.dataset[i][0].numpy().transpose(1, 2, 0)\n",
    "    img = numpy.clip(img, 0, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.xlabel(class_names[test_loader.dataset[i][1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qnjh12UbNFpV"
   },
   "source": [
    "**Define a simple model** - demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RGbLY6X-NH4O",
    "outputId": "6bd247da-cbcd-432d-c1c4-4437b6017284"
   },
   "outputs": [],
   "source": [
    "# this is not a very good baseline classifier\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(28*28*params['n_channels'], params['n_hidden'])\n",
    "        self.layer2 = nn.Linear(params['n_hidden'], params['n_classes'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"Input shape: \" + str(x.shape))\n",
    "        x = self.layer1(x.view(x.size(0), -1))\n",
    "        print(\"After layer 1: \" + str(x.shape))\n",
    "        x = torch.relu(x)\n",
    "        print(\"After relu: \" + str(x.shape))\n",
    "        x = self.layer2(x)\n",
    "        print(\"After layer 2: \" + str(x.shape))\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "# hyperparameters\n",
    "params = {\n",
    "    'n_channels': 3,  # number of channels\n",
    "    'n_hidden':   30, # change to increase parameters\n",
    "    'n_classes':  20,  # number of classes\n",
    "    'n_layers': 2      # Number of layers  \n",
    "}\n",
    "\n",
    "N = Classifier(params).to(device)\n",
    "\n",
    "# print the number of parameters - this should be included in your report\n",
    "print(f'> Number of parameters {len(torch.nn.utils.parameters_to_vector(N.parameters()))}')\n",
    "\n",
    "if len(torch.nn.utils.parameters_to_vector(N.parameters())) > 100000:\n",
    "    print(\"> Warning: you have gone over your parameter budget and will have a grade penalty!\")\n",
    "\n",
    "# initialise the optimiser\n",
    "optimiser = torch.optim.Adam(N.parameters(), lr=0.001)\n",
    "plot_data = []\n",
    "steps = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 1 - 65% accuracy currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EnhancedCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 16,kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 1* 1, 128)\n",
    "        self.fc2 = nn.Linear(128, 20)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"Input shape: \" + str(x.shape))\n",
    "        x = F.relu(self.conv1(x))\n",
    "        print(\"After conv1: \" + str(x.shape))\n",
    "        x = F.max_pool2d(x, 2) \n",
    "        print(\"After maxpool: \" + str(x.shape))\n",
    "        x = F.relu(self.conv2(x)) \n",
    "        print(\"After conv2: \" + str(x.shape))\n",
    "        x = F.max_pool2d(x, 2) \n",
    "        print(\"After maxpool2: \" + str(x.shape))\n",
    "        x = F.relu(self.conv3(x)) \n",
    "        print(\"After conv3: \" + str(x.shape))\n",
    "        x = F.max_pool2d(x, 2) \n",
    "        print(\"After maxpool3: \" + str(x.shape))\n",
    "        x = F.relu(self.conv4(x)) \n",
    "        print(\"After conv4: \" + str(x.shape))\n",
    "        x = F.max_pool2d(x, 2) \n",
    "        print(\"After maxpool4: \" + str(x.shape))\n",
    "        # x = x.view(-1, 64 * 3 * 3)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        print(\"After flattening: \" + str(x.shape))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        print(\"After fc1: \" +str(x.shape))\n",
    "        x = self.fc2(x)\n",
    "        print(\"After fc2: \" + str(x.shape))\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "N = EnhancedCNN().to(device)\n",
    "\n",
    "print(f'> Number of parameters {len(torch.nn.utils.parameters_to_vector(N.parameters()))}')\n",
    "\n",
    "optimiser = torch.optim.Adam(N.parameters(), lr=0.001)\n",
    "plot_data = []\n",
    "steps = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 2 - 70% accuracy\n",
    "\n",
    "Changes were made to training code. See comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EnhancedCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 16,kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        # self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 1* 1, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 20)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"Input shape: \" + str(x.shape))\n",
    "        x = F.relu(self.conv1(x))\n",
    "        print(\"After conv1: \" + str(x.shape))\n",
    "        x = F.max_pool2d(x, 2) \n",
    "        print(\"After maxpool: \" + str(x.shape))\n",
    "        x = F.relu(self.conv2(x)) \n",
    "        print(\"After conv2: \" + str(x.shape))\n",
    "        x = F.max_pool2d(x, 2) \n",
    "        print(\"After maxpool2: \" + str(x.shape))\n",
    "        x = F.relu(self.conv3(x)) \n",
    "        print(\"After conv3: \" + str(x.shape))\n",
    "        x = F.max_pool2d(x, 2) \n",
    "        print(\"After maxpool3: \" + str(x.shape))\n",
    "        x = F.relu(self.conv4(x)) \n",
    "        print(\"After conv4: \" + str(x.shape))\n",
    "        x = F.max_pool2d(x, 2) \n",
    "        print(\"After maxpool4: \" + str(x.shape))\n",
    "        # x = F.relu(self.conv5(x))\n",
    "        # print(\"After conv5: \" + str(x.shape))\n",
    "        # x = F.max_pool2d(x, 2)\n",
    "        # print(\"After maxpool5: \" + str(x.shape))\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        print(\"After flattening: \" + str(x.shape))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        print(\"After fc1: \" +str(x.shape))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        print(\"After fc2: \" + str(x.shape))\n",
    "        x = self.fc3(x)\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "N = EnhancedCNN().to(device)\n",
    "\n",
    "print(f'> Number of parameters {len(torch.nn.utils.parameters_to_vector(N.parameters()))}')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimiser = torch.optim.Adam(N.parameters(), lr=0.001)\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimiser, step_size=7, gamma=0.1)\n",
    "\n",
    "plot_data = []\n",
    "steps = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 3 - N/A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EnhancedCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 16,kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        # self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 1* 1, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 20)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2) \n",
    "        x = F.elu(self.conv2(x)) \n",
    "        x = F.max_pool2d(x, 2) \n",
    "        x = F.elu(self.conv3(x)) \n",
    "        x = F.max_pool2d(x, 2) \n",
    "        x = F.elu(self.conv4(x)) \n",
    "        x = F.max_pool2d(x, 2) \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = F.elu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "N = EnhancedCNN().to(device)\n",
    "\n",
    "print(f'> Number of parameters {len(torch.nn.utils.parameters_to_vector(N.parameters()))}')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Changed this\n",
    "optimiser = torch.optim.Adam(N.parameters(), lr=0.001)\n",
    "\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimiser, step_size=7, gamma=0.1)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimiser, step_size=7, gamma=0.1)\n",
    "\n",
    "plot_data = []\n",
    "steps = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1UBl0PJjY-f"
   },
   "source": [
    "**Main training and testing loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "id": "kb5909Y8D_zx",
    "outputId": "fe198374-76f9-486e-e30c-c5ea42080981"
   },
   "outputs": [],
   "source": [
    "# keep within our optimisation step budget\n",
    "while (steps < 10000):\n",
    "\n",
    "    # arrays for metrics\n",
    "    train_loss_arr = numpy.zeros(0)\n",
    "    train_acc_arr = numpy.zeros(0)\n",
    "    test_acc_arr = numpy.zeros(0)\n",
    "\n",
    "    # iterate through some of the train dateset\n",
    "    for i in range(1000):\n",
    "        x,t = next(train_iterator)\n",
    "        x,t = x.to(device), t.to(device)\n",
    "\n",
    "        # print(\"Shape: \" + str(x.shape))\n",
    "        \n",
    "        optimiser.zero_grad()\n",
    "        p = N(x)\n",
    "        pred = p.argmax(dim=1, keepdim=True)\n",
    "        # loss = torch.nn.functional.cross_entropy(p, t)\n",
    "        loss = criterion(p, t)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        steps += 1\n",
    "\n",
    "        train_loss_arr = numpy.append(train_loss_arr, loss.cpu().data)\n",
    "        train_acc_arr = numpy.append(train_acc_arr, pred.data.eq(t.view_as(pred)).float().mean().item())\n",
    "\n",
    "    scheduler.step(loss) # added as part of ATTEMPT 2 !!!!!!!!!!!!!!!!1\n",
    "\n",
    "    # iterate over the entire test dataset\n",
    "    for x,t in test_loader:\n",
    "        x,t = x.to(device), t.to(device)\n",
    "        p = N(x)\n",
    "        # loss = torch.nn.functional.cross_entropy(p, t)\n",
    "        loss = criterion(p,t)\n",
    "        pred = p.argmax(dim=1, keepdim=True)\n",
    "        test_acc_arr = numpy.append(test_acc_arr, pred.data.eq(t.view_as(pred)).float().mean().item())\n",
    "\n",
    "    # print your loss and accuracy data - include this in the final report\n",
    "    print('steps: {:.2f}, train loss: {:.3f}, train acc: {:.3f}±{:.3f}, test acc: {:.3f}±{:.3f}'.format(\n",
    "        steps, train_loss_arr.mean(),train_acc_arr.mean(),train_acc_arr.std(),test_acc_arr.mean(),test_acc_arr.std()))\n",
    "\n",
    "    # plot your accuracy graph - add a graph like this in your final report\n",
    "    plot_data.append([steps, numpy.array(train_acc_arr).mean(), numpy.array(train_acc_arr).std(), numpy.array(test_acc_arr).mean(), numpy.array(test_acc_arr).std()])\n",
    "    reward_list = []\n",
    "    plt.plot([x[0] for x in plot_data], [x[1] for x in plot_data], '-', color='tab:grey', label=\"Train accuracy\")\n",
    "    plt.fill_between([x[0] for x in plot_data], [x[1]-x[2] for x in plot_data], [x[1]+x[2] for x in plot_data], alpha=0.2, color='tab:grey')\n",
    "    plt.plot([x[0] for x in plot_data], [x[3] for x in plot_data], '-', color='tab:purple', label=\"Test accuracy\")\n",
    "    plt.fill_between([x[0] for x in plot_data], [x[3]-x[4] for x in plot_data], [x[3]+x[4] for x in plot_data], alpha=0.2, color='tab:purple')\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()\n",
    "    disp.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTFqiEHzMOVw"
   },
   "source": [
    "**Inference on dataset**\n",
    "\n",
    "This is useful for analysis but is entirely optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 907
    },
    "id": "kTzXmAdQK2c2",
    "outputId": "447feb45-9891-4a66-bdce-36e3830c2b0e"
   },
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "    img = numpy.clip(img, 0, 1)\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    img = numpy.transpose(img, (1, 2, 0))\n",
    "    plt.imshow(img)\n",
    "\n",
    "    predicted_label = numpy.argmax(predictions_array)\n",
    "    color = '#335599' if predicted_label == true_label else '#ee4433'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                  100*numpy.max(predictions_array),\n",
    "                                  class_names[true_label]),\n",
    "                                  color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(20), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = numpy.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('#ee4433')\n",
    "    thisplot[true_label].set_color('#335599')\n",
    "\n",
    "test_images, test_labels = next(test_iterator)\n",
    "test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
    "test_preds = torch.softmax(N(test_images), dim=1).data.cpu().numpy()\n",
    "num_rows = 8\n",
    "num_cols = 4\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    plot_image(i, test_preds, test_labels.cpu().numpy(), test_images.cpu().numpy()) # Used .numpy() here\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "    plot_value_array(i, test_preds, test_labels.cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
